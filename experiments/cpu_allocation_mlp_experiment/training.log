[2025-07-04 01:14:40,776] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-04 01:14:40,777] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-04 01:14:40,778] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-04 01:14:40,779] INFO - ml_pipeline - Setting up model...
[2025-07-04 01:14:40,781] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-04 01:14:40,782] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-04 01:14:40,783] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-04 01:14:40,783] INFO - ml_pipeline -   input_shape: None
[2025-07-04 01:14:40,784] INFO - ml_pipeline -   output_shape: None
[2025-07-04 01:14:40,784] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-04 01:14:40,785] INFO - ml_pipeline -   device: cpu
[2025-07-04 01:14:40,785] INFO - ml_pipeline - Setting up data loaders...
[2025-07-04 01:14:40,842] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-04 01:14:40,843] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-04 01:14:40,843] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-04 01:14:40,844] INFO - ml_pipeline - Starting model training...
[2025-07-04 01:14:41,886] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-04 01:14:41,887] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-04 01:14:42,411] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0302 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:43,663] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:44,786] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0301 | Val Loss: 0.0298 | LR: 0.001000
[2025-07-04 01:14:45,909] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0301 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:47,189] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:48,243] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:49,262] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:50,323] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0301 | Val Loss: 0.0298 | LR: 0.001000
[2025-07-04 01:14:51,389] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0301 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:52,437] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:14:53,539] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0301 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:54,907] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0300 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:55,884] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0301 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:56,873] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0301 | Val Loss: 0.0296 | LR: 0.001000
[2025-07-04 01:14:57,856] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0301 | Val Loss: 0.0298 | LR: 0.001000
[2025-07-04 01:14:58,854] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0301 | Val Loss: 0.0298 | LR: 0.001000
[2025-07-04 01:14:59,904] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0301 | Val Loss: 0.0298 | LR: 0.001000
[2025-07-04 01:15:00,957] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0301 | Val Loss: 0.0297 | LR: 0.001000
[2025-07-04 01:15:01,980] INFO - ml_pipeline - Early stopping at epoch 18
[2025-07-04 01:15:01,986] INFO - ml_pipeline - Training completed in 20.10 seconds
[2025-07-04 01:15:01,986] INFO - ml_pipeline - Training completed successfully!
[2025-07-04 01:46:44,224] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-04 01:46:44,225] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-04 01:46:44,226] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-04 01:46:44,226] INFO - ml_pipeline - Setting up model...
[2025-07-04 01:46:44,235] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-04 01:46:44,236] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-04 01:46:44,236] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-04 01:46:44,237] INFO - ml_pipeline -   input_shape: None
[2025-07-04 01:46:44,237] INFO - ml_pipeline -   output_shape: None
[2025-07-04 01:46:44,237] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-04 01:46:44,238] INFO - ml_pipeline -   device: cpu
[2025-07-04 01:46:44,238] INFO - ml_pipeline - Setting up data loaders...
[2025-07-04 01:46:44,297] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-04 01:46:44,298] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-04 01:46:44,298] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-04 01:46:44,298] INFO - ml_pipeline - Starting model training...
[2025-07-04 01:46:45,352] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-04 01:46:45,353] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-04 01:46:45,792] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0295 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:46,940] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:47,970] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0294 | Val Loss: 0.0309 | LR: 0.001000
[2025-07-04 01:46:49,103] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:50,178] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:51,284] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:52,571] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:53,613] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:54,600] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:55,649] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:56,651] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:57,683] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:58,664] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:46:59,683] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:01,025] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:02,044] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0293 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:03,059] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:04,085] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0294 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:05,105] INFO - ml_pipeline - Epoch  18 | Train Loss: 0.0293 | Val Loss: 0.0308 | LR: 0.001000
[2025-07-04 01:47:06,100] INFO - ml_pipeline - Early stopping at epoch 19
[2025-07-04 01:47:06,103] INFO - ml_pipeline - Training completed in 20.75 seconds
[2025-07-04 01:47:06,104] INFO - ml_pipeline - Training completed successfully!
[2025-07-04 01:48:18,663] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-04 01:48:18,665] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-04 01:48:18,668] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-04 01:48:18,669] INFO - ml_pipeline - Setting up model...
[2025-07-04 01:48:18,677] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-04 01:48:18,679] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-04 01:48:18,680] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-04 01:48:18,681] INFO - ml_pipeline -   input_shape: None
[2025-07-04 01:48:18,682] INFO - ml_pipeline -   output_shape: None
[2025-07-04 01:48:18,683] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-04 01:48:18,684] INFO - ml_pipeline -   device: cpu
[2025-07-04 01:48:18,685] INFO - ml_pipeline - Setting up data loaders...
[2025-07-04 01:48:18,760] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-04 01:48:18,761] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-04 01:48:18,761] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-04 01:48:18,762] INFO - ml_pipeline - Starting model training...
[2025-07-04 01:48:18,766] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-04 01:48:18,766] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-04 01:48:19,134] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0299 | Val Loss: 0.0293 | LR: 0.001000
[2025-07-04 01:48:20,199] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0298 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:21,202] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0297 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:22,255] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0297 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:23,999] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0297 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:25,057] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:26,073] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0297 | Val Loss: 0.0290 | LR: 0.001000
[2025-07-04 01:48:27,123] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0296 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:28,247] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:29,311] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:30,370] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0296 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:31,477] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0296 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:33,257] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:35,359] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0296 | Val Loss: 0.0290 | LR: 0.001000
[2025-07-04 01:48:36,413] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:37,600] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0296 | Val Loss: 0.0290 | LR: 0.001000
[2025-07-04 01:48:38,731] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:39,831] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0296 | Val Loss: 0.0290 | LR: 0.001000
[2025-07-04 01:48:40,865] INFO - ml_pipeline - Epoch  18 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:42,022] INFO - ml_pipeline - Epoch  19 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:43,041] INFO - ml_pipeline - Epoch  20 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:44,789] INFO - ml_pipeline - Epoch  21 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:45,772] INFO - ml_pipeline - Epoch  22 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:46,818] INFO - ml_pipeline - Epoch  23 | Train Loss: 0.0296 | Val Loss: 0.0292 | LR: 0.001000
[2025-07-04 01:48:47,811] INFO - ml_pipeline - Epoch  24 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:48,896] INFO - ml_pipeline - Epoch  25 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:49,904] INFO - ml_pipeline - Epoch  26 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:50,959] INFO - ml_pipeline - Epoch  27 | Train Loss: 0.0296 | Val Loss: 0.0291 | LR: 0.001000
[2025-07-04 01:48:52,117] INFO - ml_pipeline - Early stopping at epoch 28
[2025-07-04 01:48:52,131] INFO - ml_pipeline - Training completed in 33.36 seconds
[2025-07-04 01:48:52,136] INFO - ml_pipeline - Training completed successfully!
[2025-07-04 02:01:45,794] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-04 02:01:45,795] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-04 02:01:45,796] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-04 02:01:45,796] INFO - ml_pipeline - Setting up model...
[2025-07-04 02:01:45,797] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-04 02:01:45,798] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-04 02:01:45,798] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-04 02:01:45,799] INFO - ml_pipeline -   input_shape: None
[2025-07-04 02:01:45,799] INFO - ml_pipeline -   output_shape: None
[2025-07-04 02:01:45,799] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-04 02:01:45,800] INFO - ml_pipeline -   device: cpu
[2025-07-04 02:01:45,800] INFO - ml_pipeline - Setting up data loaders...
[2025-07-04 02:01:45,855] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-04 02:01:45,856] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-04 02:01:45,856] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-04 02:01:45,857] INFO - ml_pipeline - Starting model training...
[2025-07-04 02:01:46,783] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-04 02:01:46,783] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-04 02:01:47,164] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0299 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:48,361] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0298 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:49,370] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:50,401] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0298 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:51,410] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:52,471] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:53,755] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:54,805] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:55,829] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:56,839] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:57,873] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:58,873] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:01:59,849] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:01,123] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:02,155] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:03,140] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:04,138] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:05,164] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0297 | Val Loss: 0.0288 | LR: 0.001000
[2025-07-04 02:02:06,211] INFO - ml_pipeline - Epoch  18 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:07,240] INFO - ml_pipeline - Epoch  19 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:08,244] INFO - ml_pipeline - Epoch  20 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:09,686] INFO - ml_pipeline - Epoch  21 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:10,689] INFO - ml_pipeline - Epoch  22 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:11,673] INFO - ml_pipeline - Epoch  23 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:12,695] INFO - ml_pipeline - Epoch  24 | Train Loss: 0.0297 | Val Loss: 0.0287 | LR: 0.001000
[2025-07-04 02:02:13,672] INFO - ml_pipeline - Early stopping at epoch 25
[2025-07-04 02:02:13,675] INFO - ml_pipeline - Training completed in 26.89 seconds
[2025-07-04 02:02:13,675] INFO - ml_pipeline - Training completed successfully!
[2025-07-04 02:04:03,738] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-04 02:04:03,739] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-04 02:04:03,740] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-04 02:04:03,740] INFO - ml_pipeline - Setting up model...
[2025-07-04 02:04:03,742] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-04 02:04:03,743] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-04 02:04:03,743] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-04 02:04:03,744] INFO - ml_pipeline -   input_shape: None
[2025-07-04 02:04:03,745] INFO - ml_pipeline -   output_shape: None
[2025-07-04 02:04:03,745] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-04 02:04:03,745] INFO - ml_pipeline -   device: cpu
[2025-07-04 02:04:03,747] INFO - ml_pipeline - Setting up data loaders...
[2025-07-04 02:04:03,815] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-04 02:04:03,815] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-04 02:04:03,816] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-04 02:04:03,816] INFO - ml_pipeline - Starting model training...
[2025-07-04 02:04:03,818] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-04 02:04:03,819] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-04 02:04:04,262] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0298 | Val Loss: 0.0301 | LR: 0.001000
[2025-07-04 02:04:05,324] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0297 | Val Loss: 0.0303 | LR: 0.001000
[2025-07-04 02:04:06,423] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0297 | Val Loss: 0.0301 | LR: 0.001000
[2025-07-04 02:04:07,491] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:08,575] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0296 | Val Loss: 0.0303 | LR: 0.001000
[2025-07-04 02:04:09,683] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0296 | Val Loss: 0.0301 | LR: 0.001000
[2025-07-04 02:04:11,299] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:12,416] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:13,545] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:14,677] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:15,754] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:16,831] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:17,898] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:18,992] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:20,555] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:21,679] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:22,814] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:23,883] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0295 | Val Loss: 0.0301 | LR: 0.001000
[2025-07-04 02:04:24,932] INFO - ml_pipeline - Epoch  18 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:25,977] INFO - ml_pipeline - Epoch  19 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:27,053] INFO - ml_pipeline - Epoch  20 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:28,116] INFO - ml_pipeline - Epoch  21 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:29,213] INFO - ml_pipeline - Epoch  22 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:30,229] INFO - ml_pipeline - Epoch  23 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:31,845] INFO - ml_pipeline - Epoch  24 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:32,941] INFO - ml_pipeline - Epoch  25 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:34,104] INFO - ml_pipeline - Epoch  26 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:35,206] INFO - ml_pipeline - Epoch  27 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:36,284] INFO - ml_pipeline - Epoch  28 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:37,347] INFO - ml_pipeline - Epoch  29 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:38,435] INFO - ml_pipeline - Epoch  30 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:39,585] INFO - ml_pipeline - Epoch  31 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:40,687] INFO - ml_pipeline - Epoch  32 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:41,786] INFO - ml_pipeline - Epoch  33 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:42,873] INFO - ml_pipeline - Epoch  34 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:44,012] INFO - ml_pipeline - Epoch  35 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:45,490] INFO - ml_pipeline - Epoch  36 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:46,586] INFO - ml_pipeline - Epoch  37 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:47,688] INFO - ml_pipeline - Epoch  38 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:48,812] INFO - ml_pipeline - Epoch  39 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:49,898] INFO - ml_pipeline - Epoch  40 | Train Loss: 0.0296 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:50,999] INFO - ml_pipeline - Epoch  41 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:52,044] INFO - ml_pipeline - Epoch  42 | Train Loss: 0.0295 | Val Loss: 0.0300 | LR: 0.001000
[2025-07-04 02:04:53,089] INFO - ml_pipeline - Early stopping at epoch 43
[2025-07-04 02:04:53,092] INFO - ml_pipeline - Training completed in 49.27 seconds
[2025-07-04 02:04:53,093] INFO - ml_pipeline - Training completed successfully!
[2025-07-05 00:54:40,868] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-05 00:54:40,868] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-05 00:54:40,868] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-05 00:54:40,868] INFO - ml_pipeline - Setting up model...
[2025-07-05 00:54:40,869] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-05 00:54:40,869] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-05 00:54:40,869] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-05 00:54:40,869] INFO - ml_pipeline -   input_shape: None
[2025-07-05 00:54:40,870] INFO - ml_pipeline -   output_shape: None
[2025-07-05 00:54:40,870] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-05 00:54:40,870] INFO - ml_pipeline -   device: cpu
[2025-07-05 00:54:40,870] INFO - ml_pipeline - Setting up data loaders...
[2025-07-05 00:54:40,926] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-05 00:54:40,926] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-05 00:54:40,926] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-05 00:54:40,926] INFO - ml_pipeline - Starting model training...
[2025-07-05 00:54:41,752] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-05 00:54:41,753] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-05 00:54:42,045] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0305 | Val Loss: 0.0270 | LR: 0.001000
[2025-07-05 00:54:43,389] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0305 | Val Loss: 0.0270 | LR: 0.001000
[2025-07-05 00:54:44,166] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0305 | Val Loss: 0.0269 | LR: 0.001000
[2025-07-05 00:54:44,955] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0305 | Val Loss: 0.0271 | LR: 0.001000
[2025-07-05 00:54:45,728] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0305 | Val Loss: 0.0271 | LR: 0.001000
[2025-07-05 00:54:46,529] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0305 | Val Loss: 0.0269 | LR: 0.001000
[2025-07-05 00:54:47,293] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0305 | Val Loss: 0.0270 | LR: 0.001000
[2025-07-05 00:54:48,080] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0305 | Val Loss: 0.0269 | LR: 0.001000
[2025-07-05 00:54:49,094] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0305 | Val Loss: 0.0270 | LR: 0.001000
[2025-07-05 11:30:13,686] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-05 11:30:13,687] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-05 11:30:13,687] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-05 11:30:13,687] INFO - ml_pipeline - Setting up model...
[2025-07-05 11:30:13,697] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-05 11:30:13,698] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-05 11:30:13,698] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-05 11:30:13,699] INFO - ml_pipeline -   input_shape: None
[2025-07-05 11:30:13,699] INFO - ml_pipeline -   output_shape: None
[2025-07-05 11:30:13,699] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-05 11:30:13,699] INFO - ml_pipeline -   device: cpu
[2025-07-05 11:30:13,699] INFO - ml_pipeline - Setting up data loaders...
[2025-07-05 11:30:13,784] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-05 11:30:13,784] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-05 11:30:13,784] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-05 11:30:13,784] INFO - ml_pipeline - Starting model training...
[2025-07-05 11:30:15,008] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-05 11:30:15,009] INFO - ml_pipeline - Model has 11777 trainable parameters
[2025-07-05 11:30:15,429] INFO - ml_pipeline - Epoch   0 | Train Loss: 0.0297 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:17,009] INFO - ml_pipeline - Epoch   1 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:18,150] INFO - ml_pipeline - Epoch   2 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:19,078] INFO - ml_pipeline - Epoch   3 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:20,057] INFO - ml_pipeline - Epoch   4 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:21,072] INFO - ml_pipeline - Epoch   5 | Train Loss: 0.0295 | Val Loss: 0.0307 | LR: 0.001000
[2025-07-05 11:30:22,069] INFO - ml_pipeline - Epoch   6 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:22,982] INFO - ml_pipeline - Epoch   7 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:24,166] INFO - ml_pipeline - Epoch   8 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:25,059] INFO - ml_pipeline - Epoch   9 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:25,932] INFO - ml_pipeline - Epoch  10 | Train Loss: 0.0294 | Val Loss: 0.0307 | LR: 0.001000
[2025-07-05 11:30:26,809] INFO - ml_pipeline - Epoch  11 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:27,726] INFO - ml_pipeline - Epoch  12 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:28,630] INFO - ml_pipeline - Epoch  13 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:29,753] INFO - ml_pipeline - Epoch  14 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:30,760] INFO - ml_pipeline - Epoch  15 | Train Loss: 0.0294 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:31,695] INFO - ml_pipeline - Epoch  16 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:32,612] INFO - ml_pipeline - Epoch  17 | Train Loss: 0.0295 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:33,512] INFO - ml_pipeline - Epoch  18 | Train Loss: 0.0294 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:34,421] INFO - ml_pipeline - Epoch  19 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:35,739] INFO - ml_pipeline - Epoch  20 | Train Loss: 0.0294 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:36,650] INFO - ml_pipeline - Epoch  21 | Train Loss: 0.0295 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:37,525] INFO - ml_pipeline - Epoch  22 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:38,414] INFO - ml_pipeline - Epoch  23 | Train Loss: 0.0294 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:39,293] INFO - ml_pipeline - Epoch  24 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:40,186] INFO - ml_pipeline - Epoch  25 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:41,365] INFO - ml_pipeline - Epoch  26 | Train Loss: 0.0294 | Val Loss: 0.0305 | LR: 0.001000
[2025-07-05 11:30:42,299] INFO - ml_pipeline - Epoch  27 | Train Loss: 0.0294 | Val Loss: 0.0306 | LR: 0.001000
[2025-07-05 11:30:43,201] INFO - ml_pipeline - Early stopping at epoch 28
[2025-07-05 11:30:43,203] INFO - ml_pipeline - Training completed in 28.19 seconds
[2025-07-05 11:30:43,203] INFO - ml_pipeline - Training completed successfully!
[2025-07-05 11:30:43,203] INFO - ml_pipeline - Starting model evaluation...
[2025-07-06 20:16:52,306] INFO - ml_pipeline - Configuration saved to experiments/cpu_allocation_mlp_experiment/config.yaml
[2025-07-06 20:16:52,307] INFO - ml_pipeline - Initialized training pipeline for experiment: cpu_allocation_mlp_experiment
[2025-07-06 20:16:52,307] INFO - ml_pipeline - Output directory: experiments/cpu_allocation_mlp_experiment
[2025-07-06 20:18:12,285] INFO - ml_pipeline - Setting up model...
[2025-07-06 20:22:00,860] INFO - ml_pipeline - Initialized model: cpu_allocation_mlp
[2025-07-06 20:22:01,504] INFO - ml_pipeline - Model parameters: 11,777
[2025-07-06 20:22:27,289] INFO - ml_pipeline -   name: cpu_allocation_mlp
[2025-07-06 20:22:28,822] INFO - ml_pipeline -   input_shape: None
[2025-07-06 20:22:30,028] INFO - ml_pipeline -   output_shape: None
[2025-07-06 20:22:30,656] INFO - ml_pipeline -   num_parameters: 11777
[2025-07-06 20:22:31,280] INFO - ml_pipeline -   device: cpu
[2025-07-06 20:22:32,245] INFO - ml_pipeline - Setting up data loaders...
[2025-07-06 20:22:32,465] INFO - ml_pipeline - Train loader: 219 batches
[2025-07-06 20:22:32,466] INFO - ml_pipeline - Validation loader: 47 batches
[2025-07-06 20:22:32,466] INFO - ml_pipeline - Test loader: 47 batches
[2025-07-06 20:22:43,814] INFO - ml_pipeline - Starting model training...
[2025-07-06 20:24:11,144] INFO - ml_pipeline - Starting training for 100 epochs
[2025-07-06 20:24:11,905] INFO - ml_pipeline - Model has 11777 trainable parameters
